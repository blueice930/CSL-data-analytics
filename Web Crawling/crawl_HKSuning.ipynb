{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SvphuJLD141j"},"outputs":[],"source":["# Website\n","### https://www.hksuning.com/\n","\n","***"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hRy3Kw2bO0ns"},"outputs":[],"source":["# Installation\n","### If you are running this notebook for the first time, please the follow one sell, otherwise, please ignore."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"spVhs0um0boM"},"outputs":[],"source":"!pip install pyppeteer\n!pip install beautifulsoup4\n!pip install nest_asyncio\n!pip install asyncio\n!pip install lxml"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"39tTDWFOPah3"},"outputs":[],"source":["# Importing"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":"# coding=utf-8\n\nfrom pyppeteer import launch\nimport asyncio\nimport nest_asyncio\nfrom bs4 import BeautifulSoup as bs\nimport re\nfrom dataclasses import dataclass\nimport xml.etree.ElementTree as et\nimport time\nimport pandas as pd\nimport requests\nfrom multiprocessing.dummy import Pool as ThreadPool"},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":"nest_asyncio.apply()"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9C8K1jqCPqKV"},"outputs":[],"source":["# Websites that are needed to be crawling"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":"urls = [\n        \"https://search.hksuning.com/search/list?ci=503692\", # url_tablet\n        \"https://search.hksuning.com/search/list?ci=503694\", # url_laptop\n        \"https://search.hksuning.com/search/list?ci=503505\" # url_phone\n]"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"37o8-YWxP0bP"},"outputs":[],"source":["# Return all web pages of each category"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":"async def get_item(categroy: str):\n    # browser = await launch()\n    browser = await launch({\"headless\": False})\n    page = await browser.newPage()\n    await page.setViewport(viewport={'width': 1920, 'height': 1080})\n    await page.goto(categroy)\n    return page, browser"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"m7Ed6qjvQdfy"},"outputs":[],"source":["# Start crawling"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Yo3wEqHZghwb"},"outputs":[],"source":["## Get pages of each item page"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":"list_pages = []\nlist_browsers = []"},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":"async def get_page_num(page) -> int:\n    content = bs(await page.content(), 'lxml')\n    page_num = re.findall(re.compile(r\"共\\d頁\"), content.prettify())[0][1]\n    return int(page_num)"},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":"def get_all_pages():\n    for url in urls:\n        page, browser = asyncio.get_event_loop().run_until_complete(get_item(url))\n        list_pages.append(page)\n        list_browsers.append(browser)"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"There are total 2 pages about tablet\n"}],"source":"page_tablet, browser_tablet = asyncio.get_event_loop().run_until_complete(get_item(urls[0]))\n\npage_num_tablet = asyncio.get_event_loop().run_until_complete(\n        get_page_num(page_tablet)\n    )\nprint(f\"There are total {page_num_tablet} pages about tablet\")"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"There are total 2 pages about laptop\n"}],"source":"page_laptop, browser_laptop = asyncio.get_event_loop().run_until_complete(get_item(urls[1]))\n\npage_num_laptop = asyncio.get_event_loop().run_until_complete(\n        get_page_num(page_laptop)\n    )\nprint(f\"There are total {page_num_laptop} pages about laptop\")"},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"There are total 5 pages about mobile phone\n"}],"source":"page_phone, browser_phone = asyncio.get_event_loop().run_until_complete(get_item(urls[2]))\n\npage_num_phone = asyncio.get_event_loop().run_until_complete(\n        get_page_num(page_phone)\n    )\nprint(f\"There are total {page_num_phone} pages about mobile phone\")"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"J0BrgSZclmfK"},"outputs":[],"source":["## Next Page"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"K0cSf5QeZ2oU"},"outputs":[],"source":["### Have next page button?"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":"True"},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":"async def have_button(page) -> bool:\n\n    source = bs(await page.content(), 'lxml').prettify()\n    if 'name=\"ssdln_503692_bottom_pgup02-3\" style=\"display: none;\"' in source:\n        return False\n    else:\n        return True\n\nasyncio.get_event_loop().run_until_complete(have_button(page_tablet))"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["### Last page"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"async def click_last_page(page) ->bool:\n    last_btn_selector = \"#bottom_pager > div > a.prev\"\n    try:\n        await page.click(last_btn_selector)\n        return True\n    except:\n        return False\n        \n# asyncio.get_event_loop().run_until_complete(click_last_page(page_tablet))"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6x1hzpQ6lZQ9"},"outputs":[],"source":["### Click next page button"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":"async def click_next_page(page) -> bool:\n    next_btn_selector = \"#bottom_pager > div > a.next\"\n    is_next = asyncio.get_event_loop().run_until_complete(have_button(page))\n\n    if is_next:\n        await page.click(next_btn_selector)\n        return True\n    else:\n        # print(\"No next page!\")\n        return False"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["## Data storage"]},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["### Data Class"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":"@dataclass\nclass Product:\n    product_index: int\n    product_type: str\n    product_name: str\n    prodect_brand: str\n    price: float\n    avg_rating: float\n    total_comment: int\n    seller: str\n    website: str\n\n@dataclass\nclass Customer:\n    product_index: int\n    username: str\n    user_rate: float\n    rate_date: str\n    buyer_comment: str\n\n\n        \nproduct_type_dict = {\n    \"平板電腦\": \"Tablet\",\n    \"手機\": \"Mobile Phone\",\n    \"手提電腦\": \"Laptop\"\n}\n\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 500)\npd.set_option('display.max_colwidth', 50)\n\nall_product = []\nall_customer = []\ncolumn_product = ['product_index', 'product_type', 'product_name', 'prodect_brand', 'price', 'avg_rating', 'total_comment', 'seller', 'website']\ncolumn_customer = ['product_index', 'username', 'user_rate', 'rate_date', 'buyer_comment']"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"### Resolve Data"},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":"async def resolve_data(page, key):\n\n    print(f\"Getting product {key}...\")\n\n    # Click the comment tab\n    await page.click('#commentNum')\n\n    while not await page.querySelector('#rv-main > div > div.rv-main-target > div > div:nth-child(1) > div > div.rv-target-topic.clearfix > div.topic-right > div.topic-main.l > div.topic-title.clearfix') :\n        pass\n\n    time.sleep(1)\n\n    source = bs(await page.content(), 'lxml')\n\n    _product_index = key\n    \n    type_html = source.select('#pcFourth > div:nth-child(1) > div > ul > li:nth-child(5) > span > a')\n    _product_type = product_type_dict[type_html[0].get_text()]\n    \n    title = source.h1.get_text()\n    _product_name = title.replace(\"自營\", \"\").replace(\"香港倉\", \"\").strip()\n    \n    _product_brand = _product_name.split(\" \")[0]\n    \n    text_price = f\"{source.find('span', class_='integer').get_text()}.{source.find('span', class_='decimal').get_text()}\".strip()\n    _price = float(text_price)\n    \n    tmp_rate = source.select('#appraise > div.rv-wrap > div.rv-container.db > div.rv-rate.rv-bars > div.rv-rate-wrap.clearfix.rv-rate-empty > div.rv-rate-item.rv-rate-score.l > div > p.score > span')\n    _avg_rating = float(tmp_rate[0].get_text()) / 20  # Full score is 5\n    \n    try:\n        _tmp_total_comment = int(source.select('#commentNum > a > span')[0].get_text()[1])  # To be modifying\n    except IndexError:\n        _tmp_total_comment = 0\n    \n    tmp_seller = source.select('#pcFourth > div.wrapper.mt15 > div.procon-side > div.si-intro > div.si-intro-list > dl > dd')[0]\n    _seller = tmp_seller.get_text().replace(\"<dd>\", \"\").replace(\"</dd>\", \"\").strip()\n    \n    _website = dict_urls.get(key)\n\n    # print(_total_comment)\n\n    await page.evaluate(\"\"\"{window.scrollBy(0, document.body.scrollHeight);}\"\"\")\n\n    if _tmp_total_comment > 0:\n\n        resolve_customer(key)\n\n        _total_comment = len(all_customer)\n\n    one_product = [_product_index, _product_type, _product_name, _product_brand, _price, _avg_rating, _total_comment, _seller, _website]\n    all_product.append(one_product)\n\n    \n"},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":"def resolve_customer(key):\n    _product_index = key\n    \n    have_more_comment = True\n\n    p = 1\n    while have_more_comment:\n        time.sleep(0.5)\n        \n        r_url = f'https://product.hksuning.com/proxy/review/hk/ajax/review_lists/general-0000000{key}-0000000000-total-{p}-default-10-----reviewList.htm?callback=reviewList'\n\n        page_source = requests.get(r_url).text\n\n        user_regex = re.compile(r'\"nickName\":\"(\\S+)\",\"levelId\"')\n        date_regex = re.compile(r'\"publishTime\":\"(\\d+-\\d+-\\d+ \\d+:\\d+:\\d+)\",\"publishTimeStr\"')\n        comment_regex = re.compile(r'\"content\":\"(\\S+)\",\"publishTime\"')\n        rate_regex = re.compile(r'\"qualityStar\":(\\d+),\"bestFlag\"')\n\n        all_username = re.findall(user_regex, page_source)\n        all_date = re.findall(date_regex, page_source)\n        all_comment = re.findall(comment_regex, page_source)\n        all_rate = re.findall(rate_regex, page_source)\n\n        num_user = len(all_username)\n\n        for n in range(num_user):\n            _username = all_username[n]\n            _rate_date = all_rate[n]\n            _buyer_comment = all_comment[n]\n            _user_rate = all_date[n]\n\n            one_customer = [_product_index, _username, _user_rate, _rate_date, _buyer_comment]\n            all_customer.append(one_customer) \n\n        p = p + 1\n\n        rtn_msg = re.findall(re.compile(r'\"returnMsg\":\"(\\w+)\",\"reCloudDrill\"'), page_source)[0]\n\n        if \"无评价数据\" in rtn_msg:\n            have_more_comment = False\n            print(\"End\")\n            return\n        \n        print(f\"Got {key} comments page {p}\")\n      \n        # print(_rate_date)\n \n"},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"('10964124069', 'https://product.hksuning.com/0000000000/10964124069.html')\n"}],"source":"u = list(dict_urls.items())[0]\npage_tmp, browser_tmp = asyncio.get_event_loop().run_until_complete(get_item(u[1]))\nprint(u)"},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Getting product 10964124069...\nGot comments page 2\nGot comments page 3\nGot comments page 4\nGot comments page 5\nGot comments page 6\nGot comments page 7\nGot comments page 8\nGot comments page 9\nGot comments page 10\nGot comments page 11\nGot comments page 12\nGot comments page 13\nGot comments page 14\nGot comments page 15\nGot comments page 16\nGot comments page 17\nGot comments page 18\nGot comments page 19\nGot comments page 20\nGot comments page 21\nGot comments page 22\nGot comments page 23\nEnd\n  product_index product_type                                       product_name prodect_brand   price  avg_rating  total_comment seller                                            website\n0   10964124069       Tablet  APPLE IPAD AIR 10.5 64GB WIFI GOLD MUUL2ZP/A 平板電腦         APPLE  3699.0         5.0            214   香港蘇寧  https://product.hksuning.com/0000000000/109641...\n    product_index username            user_rate rate_date   buyer_comment\n0     10964124069    6***8  2019-06-20 17:25:27         5          發貨快,正品\n1     10964124069    小***姐  2019-09-29 21:40:40         5  和之前iPadpro感覺一樣\n2     10964124069    9***6  2019-09-21 19:54:59         5             非常快\n3     10964124069    7***9  2019-10-13 15:11:40         5     买家没有填写评价内容！\n4     10964124069    7***3  2019-10-11 16:22:01         5     买家没有填写评价内容！\n..            ...      ...                  ...       ...             ...\n209   10964124069    7***3  2019-05-19 12:25:53         5     买家没有填写评价内容！\n210   10964124069    2***1  2019-05-17 05:45:23         5     买家没有填写评价内容！\n211   10964124069    7***6  2019-05-16 21:30:26         5     买家没有填写评价内容！\n212   10964124069    7***8  2019-05-15 19:25:19         5     买家没有填写评价内容！\n213   10964124069    2***1  2019-05-15 19:10:24         5     买家没有填写评价内容！\n\n[214 rows x 5 columns]\n"}],"source":"asyncio.get_event_loop().run_until_complete(resolve_data(page_tmp, u[0]))\nsave_csv()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"### Store Data"},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":"def save_csv():\n    df_product = pd.DataFrame(all_product, columns=column_product)\n    df_product.to_csv(\"Products_Suning.csv\", sep=',', na_rep='N/A', encoding=\"utf_8_sig\")\n    print(df_product)\n\n    df_customer = pd.DataFrame(all_customer, columns=column_customer)\n    df_customer.to_csv(\"Customers_Suning.csv\", sep=',', na_rep='N/A', encoding=\"utf_8_sig\")\n    print(df_customer)\n\n# save_csv()"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"## URLs"},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":"dict_urls = {}"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2_pHSJaNo6YF"},"outputs":[],"source":["### Get all item url"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"next\nGot\n80\n"}],"source":"async def get_url(page):   \n\n    time.sleep(2)\n    source = bs(await page.content(), 'lxml').prettify()\n\n    item_id = re.findall(\n            re.compile(r'(?<=//product.hksuning.com/0000000000/)(\\d*).html'),\n            source\n        )\n    item_id = list(dict.fromkeys(item_id))\n    tmp_dict = {}\n    \n    for i in item_id:\n        url_patten = f\"https://product.hksuning.com/0000000000/{i}.html\"\n        tmp_dict[i] = url_patten\n        dict_urls.update(tmp_dict)\n        \n    while asyncio.get_event_loop().run_until_complete(have_button(page)):        \n        # Click next page button\n        asyncio.get_event_loop().run_until_complete(click_next_page(page))\n\n        print(\"next\")\n        # await page.screenshot({'path': 'example.png'})\n        time.sleep(2)\n        \n        # Get URLs\n        asyncio.get_event_loop().run_until_complete(get_url(page))\n\n        print(\"Got\")\n\n\nasyncio.get_event_loop().run_until_complete(get_url(page_tablet))\nprint(len(dict_urls))"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["### URLs Traversal"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":"async def traversal(page):\n    source = bs(await page.content(), 'lxml').prettify()\n    \n    for key, value in dict_urls.items():\n        page, browser = asyncio.get_event_loop().run_until_complete(get_item(value))        \n        asyncio.get_event_loop().run_until_complete(resolve_data(page, key))\n        \n        await browser.close()\n        \n# asyncio.get_event_loop().run_until_complete(traversal(page_tablet))"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9V4E4bubpBMk"},"outputs":[],"source":["## Crawl data"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":"async def get_data(page):\n    \n    # Get URLs\n    asyncio.get_event_loop().run_until_complete(get_url(page))\n    asyncio.get_event_loop().run_until_complete(traversal(page))\n    \n    \n\n# asyncio.get_event_loop().run_until_complete(get_data(page_tablet))\n# len(dict_urls)"},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":"def run_get_data(page):\n    asyncio.get_event_loop().run_until_complete(get_data(page))"},{"cell_type":"markdown","metadata":{"colab":{},"colab_type":"code","id":"noUdljtbgoEO"},"outputs":[],"source":["## Main"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":"def rtn_pages():\n    return [p for p in list_pages]"},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"Can't pickle local object 'FrameManager.__init__.<locals>.<lambda>'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m<ipython-input-73-a16667aa8970>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_get_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Event loop stopped before Future completed.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\asyncio\\futures.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\asyncio\\tasks.py\u001b[0m in \u001b[0;36m__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    247\u001b[0m                 \u001b[1;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[1;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-73-a16667aa8970>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_pages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_pages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<string>\u001b[0m in \u001b[0;36mput\u001b[1;34m(self, *args, **kwds)\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\managers.py\u001b[0m in \u001b[0;36m_callmethod\u001b[1;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethodname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m         \u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(cls, obj, protocol)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'FrameManager.__init__.<locals>.<lambda>'"]}],"source":"async def main():\n    get_all_pages()\n\n    q = multiprocessing.Manager().Queue()\n    pool = multiprocessing.Pool()\n\n    for page in list_pages:\n        q.put(page)\n    \n    for i in range(len(list_pages)):\n        pool.apply_async(run_get_data, args=(q, ))\n        \nasyncio.get_event_loop().run_until_complete(main())"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Close all browsers\nfor b in list_browsers:\n    await b.close()"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}